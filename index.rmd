---
title: ""
runtime: shiny
output:
    html_document:
        highlight: espresso
---

<!--
# Exploring the MNIST Dataset

Let's load the MNIST data using a keras' built-in function.
```{r setup, echo=TRUE, message=FALSE, warning=FALSE}
library(knitr)
library(keras)
mnist <- dataset_mnist()

cat("Dimensions of the MNIST data:\n Test: ", dim(mnist$test$x), "\nTrain: ", dim(mnist$train$x))
```

The dataset is split into a test set and a training set of 10K samples and 60K samples, respectively. Each sample is a
$28 \times 28$ grayscale pixmap.
-->

```{r visualizing-mnist, echo=FALSE, message=FALSE, warning=FALSE}
# Visualize the MNIST dataset using a shiny app.
library(knitr)
library(keras)
library(shiny)
library(tidyverse)
mnist <- dataset_mnist()
 
# Define method to draw mnist images. 'image' rotates the image by 90d for whatever reason.
rotate <- function(x) t(apply(x, 2, rev)) # 'image' rotates the image by (why?!). Gotta pass rotated matrix.
draw.pixmap <- function(mat) { image(rotate(mat), col=gray.colors(256, 0.0, 1.0), axes=FALSE) }

ui <- fluidPage(
  # Build up the user interface

  fluidRow(
    img(src='https://upload.wikimedia.org/wikipedia/commons/2/2d/Vitruvian-Icon-Gray.png', hspace="20", height="120px"),
    img(src='https://www.js-soft.com/assets/template_img/js-soft.png', height="80px")
    ),
  br(), 
  fluidRow(
    column(4,
      sliderInput('test.index', label='Sample index: ', min=1, max=10000, value=1),
      plotOutput(outputId = 'image.test', width=300, height=300)
    ),
    column(4,
      plotOutput(outputId = 'mnist.numbers.barchart')
    )
  )
)

server <- function(input, output) {
  # Define reactive outputs

  output$image.test <- renderPlot({
    # Pixmap of test image
    index = as.numeric(input$test.index)
    draw.pixmap(mnist$test$x[index,,])
  })
  output$label.test <- renderText({
    # Label of test image
    mnist$test$y[[input$test.index]]})
  output$label.train <- renderText({
    # Label of training image
    mnist$train$y[[input$train.index]]})
  output$image.train <- renderPlot({
    # Pixmap of training image
    index = as.numeric(input$train.index)
    draw.pixmap(mnist$train$x[index,,])
  })
  output$mnist.numbers.barchart <- renderPlot({
    # Barchart of the number's distributions in the MNIST dataset
    my.df <- bind_rows(tibble(labels=mnist$test$y), 
                       tibble(labels=mnist$train$y),
                       .id="Group") %>%
             mutate(Group=case_when(Group=="1" ~ "test", TRUE ~ "training")) %>%
             mutate(Group=factor(Group), labels=as.integer(labels))

    ggplot(my.df) +
      geom_bar(aes(x=labels, y=..prop.., fill=Group, color=Group), position="dodge") +
      # must create xlabels manually as I cannot declare labels as factors (bugs). See
      # https://stackoverflow.com/questions/56360383/geom-bar-changes-behavior-when-variable-is-factor
      scale_x_continuous(breaks=0:9, labels=as.character(0:9)) +
      scale_y_continuous(breaks=c()) +
      labs(x = "", y = "Proportion (rel.)", title = "Distribution of numbers in MNIST") +
      theme(legend.position=c(0.95, 0.05),
            legend.justification=c("right","bottom"),
            legend.background=element_rect(color=1),
            plot.title=element_text(hjust = 0.5)
      )
  })
}

shinyApp(ui = ui, server = server)
```

```{r keras-test}

# Normalize and flatten 28x28 images using row-major layout (which is used by tensorflow)
x.train <- array_reshape(mnist$train$x, c(nrow(mnist$train$x), 784)) / 255
x.test <- array_reshape(mnist$test$x, c(nrow(mnist$test$x), 784)) / 255

# one-hot-encode labels
y.train <- to_categorical(mnist$train$y, 10)
y.test <- to_categorical(mnist$test$y, 10)

# set up model layers
model <- keras_model_sequential() 
model %>% layer_dense(units=256, activation='relu', input_shape=c(784)) %>%
          layer_dropout(rate=0.4) %>%
          layer_dense(units=128, activation='relu') %>%
          layer_dropout(rate=0.3) %>%
          layer_dense(units=10, activation='softmax')

# define loss function and optimizer ('compile' the model)
model %>% compile(loss = 'categorical_crossentropy',
                  optimizer = optimizer_rmsprop())

# perform fit
history <- model %>% fit(
  x.train, y.train, 
  epochs = 10, batch_size = 128, 
  validation_split = 0.2
)
plot(history)
model %>% evaluate(x.test, y.test)
```

# Tensorflow Übersicht 

* Generische Bibliothek für *datenstromorientierte Numerik*
  + kann für ML & NN verwendet werden
* Hardware-agnostisch (CPU/GPU/ASIC)
* Viele Schnittstellen zu C++-Runtime (Python et al.)
* Out-of-Core fähig (!)
* Open-Source (!)
  + *'Macht-was-ihr-wollt'* Lizens (Apache)
* Sehr umfangreich u. flexibel


## TensorFlow Interfaces

* TF Core API: Low-Level TF Interface ('Bare Metal')
  + Direkte Manipulation des TF-Graphen
  + manuelle Entwicklung v. Frameworks/Tools
* Keras API:  High-Level TF API für NN
  + Zusammensetzen vordefinierter Layer-Typen
* Estimator API: High-Level TF API für klassisches ML

## Material

[Machine Learning with R and Tensorflow](https://www.youtube.com/watch?v=atiYXm7JZv0)
[keras - Deep Learning in R](https://www.datacamp.com/community/tutorials/keras-r-deep-learning)

## Keras Beispiel

```{r mnist-numbers-barchart}
library(keras)
library(tidyverse)
mnist <- dataset_mnist()

my.df <- bind_rows(tibble(labels=mnist$test$y), 
                   tibble(labels=mnist$train$y),
                   .id="Group") %>%
         mutate(Group=case_when(Group=="1" ~ "test", TRUE ~ "training")) %>%
         mutate(Group=factor(Group), labels=as.integer(labels))

ggplot(my.df) +
  geom_bar(aes(x=labels, y=..prop.., fill=Group, color=Group), position="dodge") +
  # must create xlabels manually as I cannot declare labels as factors (bugs). See
  # https://stackoverflow.com/questions/56360383/geom-bar-changes-behavior-when-variable-is-factor
  scale_x_continuous(breaks=0:9, labels=as.character(0:9)) +
  scale_y_continuous(breaks=c()) +
  labs(x = "", y = "Proportion (rel.)", title = "Distribution of numbers in MNIST") +
  theme(legend.position=c(0.95, 0.05),
        legend.justification=c("right","bottom"),
        legend.background=element_rect(color=1),
        plot.title=element_text(hjust = 0.5),
  )
```

## Quarantäne

* Gute Entwicklungsumgebung ist dadurch charakterisiert, dass einfache Absichten mit gleichermaßen einfachem Aufwand realisiert werden können. Falls Feature nicht mittels dezidiertem Parameter konfiguriert werden kann, wie groß ist DIY-Aufwand?
  + Negativbeispiel Windows 
    * VDesktop Wechsel braucht 100 Zeilen AHK Code.
    * Keine Automatische Paketverwaltung
    * *Downloader*-Programme
